# Predict Podcast Listening Time - Kaggle Competition ğŸ™ï¸

![Python](https://img.shields.io/badge/Python-3.x-blue) ![Kaggle](https://img.shields.io/badge/Kaggle-Playground%20S5E4-orange) ![Machine Learning](https://img.shields.io/badge/Machine%20Learning-Regression-green) ![License](https://img.shields.io/badge/License-MIT-blue)

This project tackles the **Predict Podcast Listening Time** competition (Kaggle Playground Series S5E4), a regression task to predict `Listening_Time_minutes` for podcast episodes based on features like episode length, genre, and host popularity. As a 3rd-year BTech CSE student specializing in data science and machine learning, I used this project to showcase my skills in data preprocessing, feature engineering, and model optimization. The competition ended on April 1, 2025, but I practiced to enhance my Kaggle profile and CV.

Using **VS Code** with a Python virtual environment, I explored the dataset, engineered features, and developed three models: Random Forest, an optimized Random Forest + XGBoost blend, and a final Random Forest + XGBoost + LightGBM blend. The best validation RMSE achieved was **0.400** with the optimized blend, positioning the approach competitively for the top 20-30% on the leaderboard (estimated based on typical Playground scores).

---

## Table of Contents ğŸ“‘

- [Overview](#overview) â„¹ï¸
- [Dataset](#dataset) ğŸ“Š
- [Methodology](#methodology) ğŸ› ï¸
- [Results](#results) âœ…
- [Next Steps](#next-steps) ğŸš€
- [How to Run](#how-to-run) âš™ï¸
- [Learnings](#learnings) ğŸ“š

---

## Overview â„¹ï¸

The **Predict Podcast Listening Time** competition (Kaggle Playground Series S5E4) is a regression task to predict `Listening_Time_minutes` for podcast episodes. This project demonstrates my ability to:
- ğŸ§¹ Preprocess complex datasets with missing values and high-cardinality features.
- ğŸ› ï¸ Engineer meaningful features to boost model performance.
- ğŸ¤– Develop and optimize ensemble models for regression.
- ğŸŒ Build a reproducible ML workflow using VS Code and Python.

The best model achieved a validation RMSE of **0.400**, competitive for the top 20-30% on the Kaggle leaderboard (estimated).

---

## Dataset ğŸ“Š

- **Source**: Kaggle Playground Series S5E4 ([link](https://www.kaggle.com/competitions/playground-series-s5e4)).
- **Size**: 750,000 training rows, 500,000 test rows.
- **Features** (12):
  - ğŸ”¢ **Numerical**: `Episode_Length_minutes`, `Host_Popularity_percentage`, `Guest_Popularity_percentage`, `Number_of_Ads`.
  - ğŸ“ **Categorical**: `Podcast_Name`, `Episode_Title`, `Genre`, `Publication_Day`, `Publication_Time`, `Episode_Sentiment`.
  - ğŸ†” **Other**: `id` (identifier).
- **Target**: `Listening_Time_minutes` (continuous, 0-119.97 minutes).
- **Challenges**:
  - â“ Missing values: `Episode_Length_minutes` (11.6%), `Guest_Popularity_percentage` (19.5%), `Number_of_Ads` (<0.1%).
  - ğŸ“š High-cardinality categoricals: `Podcast_Name`, `Episode_Title`.
  - â° Categorical `Publication_Time` (e.g., "Morning," "Night") required special handling.

---

## Methodology ğŸ› ï¸

The project was executed in **VS Code** with Python, using libraries like `pandas`, `scikit-learn`, `xgboost`, and `lightgbm`. The workflow included:

### 1. Exploratory Data Analysis (EDA) ğŸ“ˆ
- **Script**: `eda.py`
- **Findings**:
  - ğŸ¯ Target distribution: Near-normal (skewness 0.351), no log-transformation needed.
  - ğŸ”— Strong correlation between `Episode_Length_minutes` and `Listening_Time_minutes`.
  - ğŸ­ `Genre` and `Host_Popularity_percentage` showed potential for feature interactions.
  - ğŸ“Š Visualized distributions, correlations, and categorical impacts using `seaborn` and `matplotlib`.

### 2. Data Preprocessing ğŸ§¹
- **Script**: `preprocess.py`
- **Steps**:
  - **Missing Values**:
    - ğŸ› ï¸ Imputed `Episode_Length_minutes`, `Guest_Popularity_percentage`, `Number_of_Ads` with median.
  - **Categorical Encoding**:
    - ğŸ¯ Target encoding for `Podcast_Name`, `Episode_Title` (mapped to mean `Listening_Time_minutes`).
    - ğŸ·ï¸ `LabelEncoder` for `Genre`, `Publication_Day`, `Publication_Time`, `Episode_Sentiment`.
  - **Feature Engineering**:
    - â° `Publication_Hour`: Mapped `Publication_Time` (e.g., Night â†’ 22) with cyclic encoding (`Publication_Hour_sin`, `Publication_Hour_cos`).
    - ğŸŒŸ `Genre_Popularity`: Mean `Listening_Time_minutes` per `Genre`.
    - ğŸ¤ `Genre_Host_Interaction`: Product of `Genre` and `Host_Popularity_percentage`.
    - ğŸ“ `Length_to_Listening_Ratio`: `Episode_Length_minutes` / (`Listening_Time_minutes` + 1).
  - **Scaling**:
    - âš–ï¸ Standardized numerical features with `StandardScaler`.
- **Output**: `train_preprocessed.csv`, `test_preprocessed.csv`.

### 3. Modeling ğŸ¤–
Three models were developed to predict `Listening_Time_minutes`:

#### Random Forest (`model.py`)
- **Algorithm**: `RandomForestRegressor` (n_estimators=100, n_jobs=-1).
- **Validation RMSE**: 0.421.
- **Details**: Robust baseline, leveraging all preprocessed features. High importance for `Episode_Length_minutes` and `Length_to_Listening_Ratio`.
- **Output**: `submission.csv`.

#### Optimized Blend (`optimized_blend.py`)
- **Algorithm**: Weighted blend of Random Forest (70%) and XGBoost (30%).
  - ğŸŒ² Random Forest: Same as above.
  - ğŸš€ XGBoost: `XGBRegressor` (n_estimators=300, learning_rate=0.05, max_depth=7).
- **Validation RMSE**: 0.400 (best).
- **Details**: Improved over Random Forest by combining strengths, with weights favoring Random Forest.
- **Output**: `optimized_blend_submission.csv`.

#### Final Blend (`final_blend.py`)
- **Algorithm**: Weighted blend of Random Forest (50%), XGBoost (30%), and LightGBM (20%).
  - ğŸŒ² Random Forest: Same as above.
  - ğŸš€ XGBoost: Same as optimized blend.
  - ğŸ’¡ LightGBM: `LGBMRegressor` (n_estimators=500, learning_rate=0.03, max_depth=8, num_leaves=31).
- **Validation RMSE**: 0.418.
- **Details**: Added LightGBM for diversity, but slightly worse due to untuned weights.
- **Output**: `final_blend_submission.csv`.

### 4. Evaluation ğŸ“Š
- **Metric**: Root Mean Squared Error (RMSE) on validation set (20% split, random_state=42).
- **Results**:
  - ğŸŒ² Random Forest: 0.421
  - ğŸ¤ Optimized Blend (RF + XGBoost): 0.400
  - ğŸ”— Final Blend (RF + XGBoost + LightGBM): 0.418
- **Leaderboard**: Submissions made to Kaggleâ€™s late leaderboard to compare public RMSE (awaiting results).

### 5. Tools and Environment ğŸ–¥ï¸
- **IDE**: VS Code with Python virtual environment.
- **Libraries**: `pandas`, `numpy`, `scikit-learn`, `xgboost`, `lightgbm`, `seaborn`, `matplotlib`.
- **Data**: Managed in `data/` folder (`train.csv`, `test.csv`, preprocessed CSVs).
- **Scripts**:
  - ğŸ“ˆ `eda.py`: Data exploration and visualization.
  - ğŸ§¹ `preprocess.py`: Data cleaning, encoding, feature engineering.
  - ğŸŒ² `model.py`: Random Forest model.
  - ğŸ¤ `optimized_blend.py`: RF + XGBoost blend.
  - ğŸ”— `final_blend.py`: RF + XGBoost + LightGBM blend.

---

## Results âœ…

- **Best Model**: Optimized Blend (Random Forest 70%, XGBoost 30%) with validation RMSE **0.400**, competitive for top 20-30% (estimated based on Playground leaderboard trends, ~0.3-0.4 for top ranks).
- **Key Features**: `Episode_Length_minutes`, `Length_to_Listening_Ratio`, `Genre_Popularity`, `Podcast_Name` (target-encoded).
- **Submissions**: Generated `submission.csv`, `optimized_blend_submission.csv`, `final_blend_submission.csv` for Kaggle evaluation.

---

## Next Steps ğŸš€

- **Submit and Compare**: Check public RMSE on Kaggleâ€™s late leaderboard to confirm ranking.
- **Further Optimization**:
  - ğŸ”§ Tune LightGBM hyperparameters (e.g., grid search for `num_leaves`, `learning_rate`).
  - ğŸ”— Experiment with stacking models instead of blending.
  - ğŸŒŸ Add more interaction features (e.g., `Genre_Guest_Interaction`).
- **Portfolio**:
  - ğŸ“‚ Push to GitHub for public sharing.
  - ğŸ“ Publish a Kaggle notebook with EDA, preprocessing, and best model.
- **Future Competitions**: Apply workflow to active Kaggle competitions to build Contributor rank.

---

## How to Run âš™ï¸

1. **Setup**:
   ```bash
   python -m venv venv
   .\venv\Scripts\activate  # Windows
   pip install pandas numpy scikit-learn xgboost lightgbm seaborn matplotlib
2. **Prepare Data**:
   ğŸ“‚ Place train.csv, test.csv in data/ folder (download from Kaggle).

3. **Run Scripts**:
   python eda.py
   python preprocess.py
   python model.py
   python optimized_blend.py
   python final_blend.py

4. **Submit**:
   ğŸ“¤ Upload generated CSV files to Kaggleâ€™s submission page.


#### Learnings ğŸ“š
- ğŸ§¹ Mastered preprocessing for high-cardinality and categorical features.
- ğŸ¤– Gained experience with ensemble methods (Random Forest, XGBoost, LightGBM).
- ğŸŒŸ Improved feature engineering (target encoding, cyclic encoding, interactions).
- âš™ï¸ Developed a reproducible ML workflow in VS Code.
- **This project highlights my ability to tackle real-world ML problems and supports my journey to becoming a proficient data scientist.**
